{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "%matplotlib inline\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(shape = shape, stddev = 0.1), name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    return tf.Variable(tf.zeros(shape = shape), name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "g_dim = 100\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "def deconv2d(x, W, output_shape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "x_d=tf.placeholder(tf.float32,shape=[None,784])\n",
    "x_g=tf.placeholder(tf.float32,shape=[None,g_dim])\n",
    "weights={\n",
    "    \"w_d1\":weight_variable([5,5,1,32],\"w_d1\"),\n",
    "    \"w_d2\":weight_variable([5,5,32,64],\"w_d2\"),\n",
    "    \"w_d3\":weight_variable([7*7*64,1],\"w_d3\"),\n",
    "    \n",
    "    \"w_g1\" : weight_variable([g_dim, 4 * 4 * 64], \"w_g1\"),\n",
    "    \"w_g2\" : weight_variable([5, 5, 32, 64], \"w_g2\"),\n",
    "    \"w_g3\" : weight_variable([5, 5, 16, 32], \"w_g3\"),\n",
    "    \"w_g4\" : weight_variable([5, 5, 1, 16], \"w_g4\")\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b_d1\" : bias_variable([32], \"b_d1\"),\n",
    "    \"b_d2\" : bias_variable([64], \"b_d2\"),\n",
    "    \"b_d3\" : bias_variable([1], \"b_d3\"),\n",
    "    \"b_g1\" : bias_variable([4 * 4 * 64], \"b_g1\"),\n",
    "    \"b_g2\" : bias_variable([32], \"b_g2\"),\n",
    "    \"b_g3\" : bias_variable([16], \"b_g3\"),\n",
    "    \"b_g4\" : bias_variable([1], \"b_g4\"),\n",
    "}\n",
    "\n",
    "var_d = [weights[\"w_d1\"], weights[\"w_d2\"], weights[\"w_d3\"], biases[\"b_d1\"], biases[\"b_d2\"], biases[\"b_d3\"]]\n",
    "var_g = [weights[\"w_g1\"], weights[\"w_g2\"],weights[\"w_g3\"], weights[\"w_g4\"], biases[\"b_g1\"], biases[\"b_g2\"],biases[\"b_g3\"], biases[\"b_g4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    #100x1\n",
    "    h_g1=tf.nn.relu(tf.add(tf.matmul(z,weights[\"w_g1\"]),biases[\"b_g1\"]))\n",
    "    #-1x4*4*128\n",
    "    h_g1_reshape=tf.reshape(h_g1,[-1,4,4,64])\n",
    "    \n",
    "    output_shape_g2=tf.stack([tf.shape(z)[0],7,7,32])\n",
    "    h_g2=tf.nn.relu(tf.add(deconv2d(h_g1_reshape,weights[\"w_g2\"],output_shape_g2),biases[\"b_g2\"]))\n",
    "    \n",
    "    output_shape_g3=tf.stack([tf.shape(z)[0],14,14,16])\n",
    "    h_g3=tf.nn.relu(tf.add(deconv2d(h_g2,weights[\"w_g3\"],output_shape_g3),biases[\"b_g3\"]))\n",
    "    \n",
    "    output_shape_g4=tf.stack([tf.shape(z)[0],28,28,1])\n",
    "    h_g4=tf.nn.tanh(tf.add(deconv2d(h_g3,weights[\"w_g4\"],output_shape_g4),biases[\"b_g4\"]))\n",
    "    \n",
    "    return h_g4\n",
    "\n",
    "def discriminator(x):\n",
    "    x_reshape=tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    h_d1=tf.nn.relu(tf.add(conv2d(x_reshape,weights[\"w_d1\"]),biases[\"b_d1\"]))\n",
    "    h_d2=tf.nn.relu(tf.add(conv2d(h_d1,weights[\"w_d2\"]),biases[\"b_d2\"]))\n",
    "    h_d2_reshape=tf.reshape(h_d2,[-1,7*7*64])\n",
    "    h_d3=tf.nn.sigmoid(tf.add(tf.matmul(h_d2_reshape,weights[\"w_d3\"]),biases[\"b_d3\"]))\n",
    "    return h_d3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m,n):\n",
    "    return np.random.uniform(-1.,1.,size=[m,n])\n",
    "\n",
    "g_sample=generator(x_g)\n",
    "d_real=discriminator(x_d)\n",
    "d_fake=discriminator(g_sample)\n",
    "\n",
    "d_loss=-tf.reduce_mean(tf.log(d_real)+tf.log(1.-d_fake))\n",
    "g_loss=-tf.reduce_mean(tf.log(d_fake))\n",
    "\n",
    "d_optimizer=tf.train.AdamOptimizer(0.0001).minimize(d_loss,var_list=var_d)\n",
    "g_optimizer=tf.train.AdamOptimizer(0.001).minimize(g_loss,var_list=var_g)\n",
    "\n",
    "def plot(samples):\n",
    "    fig=plt.figure(figsize=(4,4))\n",
    "    gs=gridspec.GridSpec(4,4)\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax=plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28,28,),cmap='gray')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, discriminator loss 1.57141  generator loss 0.80381\n",
      "step 100, discriminator loss 2.22205  generator loss 0.44675\n",
      "step 200, discriminator loss 1.34972  generator loss 1.52780\n",
      "step 300, discriminator loss 2.12599  generator loss 0.92300\n",
      "step 400, discriminator loss 2.73131  generator loss 0.42532\n",
      "step 500, discriminator loss 2.09176  generator loss 0.53778\n",
      "step 600, discriminator loss 1.91716  generator loss 0.54869\n",
      "step 700, discriminator loss 1.92316  generator loss 0.55509\n",
      "step 800, discriminator loss 1.78746  generator loss 0.66446\n",
      "step 900, discriminator loss 1.36992  generator loss 0.79376\n",
      "step 1000, discriminator loss 1.06971  generator loss 0.87361\n",
      "step 2000, discriminator loss 1.12251  generator loss 0.77568\n",
      "step 3000, discriminator loss 0.68136  generator loss 1.48890\n",
      "step 4000, discriminator loss 0.09073  generator loss 2.64718\n",
      "step 5000, discriminator loss 0.04602  generator loss 4.03345\n",
      "step 6000, discriminator loss 0.00873  generator loss 5.98883\n",
      "step 7000, discriminator loss 0.00258  generator loss 6.70304\n",
      "step 8000, discriminator loss 0.00191  generator loss 6.29935\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "for step in range(20001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    _, d_loss_train = sess.run([d_optimizer, d_loss], feed_dict = {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "    _, g_loss_train = sess.run([g_optimizer, g_loss], feed_dict = {x_g: sample_Z(batch_size, g_dim)})\n",
    "\n",
    "    if step <= 1000:\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d, discriminator loss %.5f\" % (step, d_loss_train)),\n",
    "            print(\" generator loss %.5f\" % (g_loss_train))\n",
    "        if step % 1000 == 0: \n",
    "            g_sample_plot = g_sample.eval(feed_dict = {x_g: sample_Z(16, g_dim)})\n",
    "            plot(g_sample_plot)\n",
    "    else:\n",
    "        if step % 1000 == 0:\n",
    "            print(\"step %d, discriminator loss %.5f\" % (step, d_loss_train)),\n",
    "            print(\" generator loss %.5f\" % (g_loss_train))\n",
    "        if step % 2000 == 0: \n",
    "            g_sample_plot = g_sample.eval(feed_dict = {x_g: sample_Z(16, g_dim)})\n",
    "            plot(g_sample_plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
